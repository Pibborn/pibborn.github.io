<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Mattia  Cerrato | Fair & Interpretable Representation Learning</title>
<meta name="description" content="Post-Doc at JGU Mainz
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css " />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üê¢</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/projects/fair_interpretable/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Mattia</span>   Cerrato
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
           <!-- skip class in header -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Fair & Interpretable Representation Learning</h1>
    <p class="post-description">Understandable neural networks for fair representation learning.</p>
  </header>

  <article>
    <p>Representation learning algorithms based on neural networks are being employed extensively in information retrieval and data mining applications.
The social impact of what the general public refers to as ‚ÄúAI‚Äù is now a topic of much discussion, with regulators in the EU even putting forward legal proposals which would require practitioners to ‚Äú[‚Ä¶] minimise the risk of unfair biases embedded in the model [‚Ä¶]‚Äù.</p>

<p>The concern is that <strong>models trained on biased data might then learn those biases</strong>, therefore perpetuating historical discrimination against certain groups of individuals.</p>

<div class="row">
    <div class="col-sm mt-6 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/doctor.png" alt="" title="example image" />
    </div>
    <div class="col-sm mt-6 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/scores.svg" alt="" title="example image" />
    </div>
</div>
<div class="caption">
    Left: a translation model displays a gender bias. Translating English to Turkish and back shows how, when information is not sufficient, some inductive bias is needed to complete a translation task. When in doubt, the model performs the "most likely translation" by assuming that the nurse is female and the doctor is male. Right: the distribution of credit scores in the US depending on ethnicity. While credit scoring is an ethnicity-independent measurement, the difference between groups shows up as a result. Images from fairmlbook.org.
</div>

<p>In this situation, one needs to be concerned with the fairness of a neural network, i.e. whether it is relying on sensitive, law-protected information such as ethnicity or gender to undertake its decisions. One possible approach is to remove information about the sensitive attribute from the model‚Äôs internal representations. 
These technique are commonly referred to as ‚Äúfair representation learning‚Äù. 
These methodologies learn a projection \(f: \mathcal{X} \to \mathcal{Z}\) into a latent space where it can be shown that the information about $s$ is minimal.</p>

<p>However, one issue in the area of fair representation learning is interpretability. The projection into a latent space makes it hard to investigate <strong>why</strong> the decisions have been undertaken. This is in open contradiction with recent EU legislation, which calls for a right to an explanation for individuals which are subject to automatic decision systems (General Data Protection Regulation (GDPR), Recital 71).</p>

<p>In this context, DNNs that are <strong>fair</strong> might still not be <strong>transparent</strong> enough to be applied in real-world scenarios.</p>

<p>Our current proposal is to employ a custom neural architecture which performs <strong>feature corrections</strong> for fairness.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img style="text-align:center" class="img-fluid rounded z-depth-1" src="/assets/img/sellme.svg" alt="" title="example image" />
    </div>
</div>
<div class="caption">
    Instead of projecting into latent space, a possible interpretable architecture maps back onto feature space by learning a correction vector which matches in size with X. This model was trained on a US dataset dealing with law school admissions. Underpriviledged groups get a small boost to their average LSAT score so that admissions may be balanced between groups.
</div>

<p>If you are interested in working in this topic, I have several possible avenues of research starting from this idea.</p>

<ul>
  <li>Extending the architecture so that it may handle categorical and ordinal features naturally.</li>
  <li>Limit the maximum amount of correction for each feature as a parameter which can be chosen by the user.</li>
  <li>Investigate the connections to the counterfactual fairness literature.</li>
</ul>

<p>Some of the skills you will develop and knowledge you will gain by working on this topic:</p>

<ul>
  <li>Tensorflow/Pytorch fundamentals</li>
  <li>Experimental tracking</li>
  <li>Neural architectures for domain adaptation and fairness</li>
</ul>

<p>Please contact me via email if interested: <strong>mcerrato at uni dash mainz dot de</strong>.</p>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Mattia  Cerrato.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
